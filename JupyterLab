import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

def random_flipped_img(images, labels, flip_ratio):
    num_flips = int(len(images) * flip_ratio)
    random_choice = np.random.choice(len(images), num_flips, replace=False)
    flipped_images = []
    flipped_labels = []
    for i, (img,label) in enumerate(zip(images,labels)):
        if i in random_choice:
            flipped_img = np.flip(img, axis=0)
            flipped_images.append(flipped_img)
            flipped_labels.append(1) # 1 for flip
        else:
            flipped_images.append(img)
            flipped_labels.append(0) # 0 for not flip
    return flipped_images, flipped_labels

# Load STL-10 dataset
stl10_dataset, info = tfds.load('stl10', split=['train', 'test'], with_info=True)

# Extract images and labels
train_images = []
train_labels = []
test_images = []
test_labels = []

# Load train images and labels
for example in tfds.as_numpy(stl10_dataset[0]):
    train_images.append(example['image'])
    train_labels.append(example['label'])

# Load test images and labels
for example in tfds.as_numpy(stl10_dataset[1]):
    test_images.append(example['image'])
    test_labels.append(example['label'])

# Convert lists to numpy arrays
train_images = np.array(train_images)
train_labels = np.array(train_labels)
test_images = np.array(test_images)
test_labels = np.array(test_labels)
# Amount of Train and Test
train_num = 80
test_num = 20

# Select random 10 images from the train set
random_indices_train = np.random.choice(len(train_images), train_num, replace=False)
selected_train_images = train_images[random_indices_train]
selected_train_labels = train_labels[random_indices_train]

# Apply flipping with 50% probability to the selected train images
flip_ratio = 0.5  # 50% flip ratio
flipped_train_images, flipped_train_labels = random_flipped_img(selected_train_images, selected_train_labels, flip_ratio)

# Select random 10 images from the test set
random_indices_test = np.random.choice(len(test_images), test_num, replace=False)
selected_test_images = test_images[random_indices_test]
selected_test_labels = test_labels[random_indices_test]

# Apply flipping with 50% probability to the selected test images
flipped_test_images, flipped_test_labels = random_flipped_img(selected_test_images, selected_test_labels, flip_ratio)

# Plot original train images
plt.figure(figsize=(20, 20))
for i, img in enumerate(selected_train_images):
    plt.subplot(8, 10, i + 1)
    plt.imshow(img)
    plt.axis('off')
    plt.title(f'Label: {int(selected_train_labels[i])}')

# Plot flipped train images
plt.figure(figsize=(20, 20))
for i, (img, label) in enumerate(zip(flipped_train_images, flipped_train_labels)):
    plt.subplot(8, 10, i + 1)
    plt.imshow(img)
    plt.axis('off')
    plt.title(f'Label: {int(label)}')


# Plot original test images
plt.figure(figsize=(20, 4))
for i, img in enumerate(selected_test_images):
    plt.subplot(2, 10, i + 1)
    plt.imshow(img)
    plt.axis('off')
    plt.title(f'Label: {int(selected_test_labels[i])}')

# Plot flipped test images
plt.figure(figsize=(20, 4))
for i, (img, label) in enumerate(zip(flipped_test_images, flipped_test_labels)):
    plt.subplot(2, 10, i + 1)
    plt.imshow(img)
    plt.axis('off')
    plt.title(f'Label: {int(label)}')

plt.show()


def resize_images(images):
    resized_images = tf.image.resize(images, (28, 28))
    return resized_images

# Your code for loading data, flipping images, and extracting labels remains the same

# Convert to numpy arrays and normalize
train_images = np.array(flipped_train_images) / 255.0
train_labels = np.array(flipped_train_labels)
test_images = np.array(flipped_test_images) / 255.0
test_labels = np.array(flipped_test_labels)

# Resize images
train_images_resized = resize_images(train_images)
test_images_resized = resize_images(test_images)
input_shape = train_images_resized[0].shape
# Define CNN model
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Compile model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train model
history = model.fit(
    train_images_resized,
    train_labels,
    epochs=50,
    validation_data=(test_images_resized, test_labels)
)

from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Define function to resize images
def resize_images(images):
    resized_images = tf.image.resize(images, (28, 28))
    return resized_images

# Resize images
train_images_resized = resize_images(flipped_train_images)
test_images_resized = resize_images(flipped_test_images)

# Flatten images for decision tree model
train_images_flattened = tf.reshape(train_images_resized, (train_images_resized.shape[0], -1))
test_images_flattened = tf.reshape(test_images_resized, (test_images_resized.shape[0], -1))

# Train decision tree model
decision_tree_model = DecisionTreeClassifier()
decision_tree_model.fit(train_images_flattened, flipped_train_labels)

# Evaluate decision tree model
decision_tree_accuracy = decision_tree_model.score(test_images_flattened, flipped_test_labels)
print("Decision Tree Accuracy:", decision_tree_accuracy)

# Make predictions on test images using decision tree
decision_tree_predictions = decision_tree_model.predict(test_images_flattened)
print("Decision Tree Predictions:", decision_tree_predictions)

# Make predictions on n test images
num_images_to_predict = 20
predicted_labels = []

# Resize test images
test_images_resized = resize_images(test_images)

for i in range(num_images_to_predict):
    # Make prediction on a single image
    prediction = model.predict(np.expand_dims(test_images_resized[i], axis=0))
    # Get the index of the highest probability prediction
    predicted_label = np.argmax(prediction)
    predicted_labels.append(predicted_label)

print("Predicted labels of images:", predicted_labels)
